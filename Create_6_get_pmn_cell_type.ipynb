{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query timestamp: 2023-05-25 08:10:01.254304+00:00 (1685002201.254304)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import utils\n",
    "import connectome_create\n",
    "# viz_method = one of ['itkwidgets', 'vtk']\n",
    "viz_method = 'vtk'\n",
    "\n",
    "# import some of our favorite packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "# import nglui.statebuilder as ngstbld\n",
    "\n",
    "# # this is the EM specific package for querying the EM data\n",
    "from caveclient import CAVEclient\n",
    "\n",
    "\n",
    "# from meshparty import trimesh_io, trimesh_vtk\n",
    "# from meshparty import skeletonize, skeleton_io, skeleton\n",
    "# import cloudvolume\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import json\n",
    "\n",
    "# with open(Path.home() / '.cloudvolume/secrets/'/'cave-secret.json') as f:\n",
    "#         tokens = json.load(f)\n",
    "        \n",
    "# seg_source = 'graphene://https://cave.fanc-fly.com/segmentation/table/mar2021_prod'\n",
    "# cv = cloudvolume.CloudVolume(cloudpath=seg_source, use_https=True, secrets=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datastack_name = 'fanc_production_mar2021'\n",
    "\n",
    "client = CAVEclient(datastack_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# client = CAVEclient()\n",
    "\n",
    "# # if not os.path.isfile(os.path.expanduser(\"~/.cloudvolume/secrets/cave-secret.json\")):\n",
    "# client.auth.get_new_token(open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have not yet setup this computer, uncomment this below line\n",
    "# paste the token from the website in, and run the line\n",
    "\n",
    "# client.auth.save_token(token=\"c14cd7a3e18a1a697716a399afbf5778\", overwrite=True)\n",
    "\n",
    "# then comment or delete the line as you don't need to run it on this computer  again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pickle file ./dfs_pre_to_mn/pre_to_mn_df_matched_to_pool_20230525.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1472, 69)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_to_mn_df = connectome_create.load_pre_to_mn_df(ext='matched_to_pool')\n",
    "pre_to_mn_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add local neuron classification and hemilineage to matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pmn_annotation_table = client.materialize.query_table('t1l_local_premotor_table_v0',timestamp=timestamp)\n",
    "# pmn_annotation_table = client.materialize.query_table('t1l_local_premotor_table_v1',timestamp=timestamp)\n",
    "# pmn_annotation_table = client.materialize.query_table('t1l_local_premotor_table_v2',timestamp=timestamp)\n",
    "# pmn_annotation_table = client.materialize.query_table('t1l_local_premotor_table_v3',timestamp=timestamp)\n",
    "# pmn_annotation_table = client.materialize.query_table('t1l_local_premotor_table_v3',timestamp='now')\n",
    "# pmn_annotation_table = client.materialize.live_live_query('t1l_local_premotor_table_v3',timestamp='now')\n",
    "pmn_annotation_table = client.materialize.query_table('t1l_local_premotor_table_v3',timestamp=connectome_create.get_timestamp())\n",
    "\n",
    "\n",
    "# pmn_annotation_table.classification_system.value_counts()\n",
    "# pmn_annotation_table.cell_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_anypoint(segid, dataset_name = 'fanc_production_mar2021'):\n",
    "#     dataset = dataset_name\n",
    "#     client = CAVEclient(dataset)\n",
    "    \n",
    "#     lvl2ids = client.chunkedgraph.get_leaves(segid, stop_layer=2)\n",
    "#     l2attrs = client.l2cache.get_l2data(lvl2ids,['size_nm3'])\n",
    "#     return l2attrs\n",
    "#     print(l2attrs.values[0].rep_coord_nm)\n",
    "#     v = []\n",
    "#     for i in l2attrs.values():\n",
    "#         if len(i) >0:\n",
    "#             j = i['size_nm3']\n",
    "#             v.append(j)\n",
    "#     volumes = np.array(v)\n",
    "\n",
    "#     tot_vol_um3 = np.sum(volumes)/(1000*1000*1000)\n",
    "    \n",
    "#     l2attrs_area = client.l2cache.get_l2data(lvl2ids,['area_nm2'])\n",
    "    \n",
    "#     v = []\n",
    "#     for i in l2attrs_area.values():\n",
    "#         if len(i) >0:\n",
    "#             j = i['area_nm2']\n",
    "#             v.append(j)\n",
    "#     areas = np.array(v).astype(float)\n",
    "\n",
    "#     tot_area_um2 = np.sum(areas)/(1000*1000)\n",
    "    \n",
    "#     return tot_vol_um3, tot_area_um2\n",
    "\n",
    "# get_anypoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_df_csv(pmn_annotation_table,name='t1l_local_premotor_table_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dfs_saved/t1l_local_premns_to_type_20230525.csv\n",
      "(622, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[648518346490456924,\n",
       " 648518346502962675,\n",
       " 648518346486234466,\n",
       " 648518346488638136,\n",
       " 648518346489466457,\n",
       " 648518346491049763,\n",
       " 648518346504043616,\n",
       " 648518346496946404,\n",
       " 648518346466042672,\n",
       " 648518346495640738,\n",
       " 648518346510012454,\n",
       " 648518346496378487,\n",
       " 648518346491989871,\n",
       " 648518346504101672,\n",
       " 648518346486798844,\n",
       " 648518346486572932,\n",
       " 648518346510020902,\n",
       " 648518346496031178,\n",
       " 648518346478032109,\n",
       " 648518346488594313,\n",
       " 648518346465100661,\n",
       " 648518346517435946,\n",
       " 648518346498115482,\n",
       " 648518346477699036,\n",
       " 648518346482935973,\n",
       " 648518346487768898,\n",
       " 648518346508899647,\n",
       " 648518346486261346,\n",
       " 648518346521580793,\n",
       " 648518346480658433,\n",
       " 648518346475308344,\n",
       " 648518346486230114,\n",
       " 648518346497323032,\n",
       " 648518346495907403,\n",
       " 648518346477661198,\n",
       " 648518346494744491,\n",
       " 648518346497017240,\n",
       " 648518346507516793,\n",
       " 648518346494246023,\n",
       " 648518346466050864,\n",
       " 648518346507490169,\n",
       " 648518346481836221,\n",
       " 648518346498572784,\n",
       " 648518346489785036,\n",
       " 648518346493114544,\n",
       " 648518346492758715,\n",
       " 648518346496378743,\n",
       " 648518346490452234]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many of the pmn seg is are not in the matrix\n",
    "pmn_index = pre_to_mn_df.index.to_frame()\n",
    "pmn_index = pmn_index.set_index(keys=['segID'],drop=False)\n",
    "local_pmns  = pmn_index.loc[pmn_index.cell_class=='local']\n",
    "\n",
    "\n",
    "local_pmns_to_type = local_pmns.loc[~local_pmns.segID.isin(pmn_annotation_table.pt_root_id)]\n",
    "utils.save_df_csv(local_pmns_to_type,name='t1l_local_premns_to_type')\n",
    "local_pmns_to_type.segID.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get points from segIDs, then find the newsegID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just add classifications and hemilineage to the index, then put the index back on and reorder\n",
    "pmn_index = pre_to_mn_df.index.to_frame()\n",
    "pmn_index = pmn_index.set_index(keys=['segID'],drop=False)\n",
    "\n",
    "pmn_index['classification_system'] = None\n",
    "pmn_index['cell_type'] = None\n",
    "\n",
    "for clsys in pmn_annotation_table.classification_system.unique():\n",
    "    # print(clsys)\n",
    "    pmn_index.loc[pmn_index.segID.isin(pmn_annotation_table.loc[pmn_annotation_table.classification_system==clsys,'pt_root_id']),'classification_system'] = clsys\n",
    "    # print(pmn_index.loc[pmn_index.classification_system == clsys].shape)\n",
    "    \n",
    "\n",
    "for ctype in pmn_annotation_table.cell_type.unique():\n",
    "    pmn_index.loc[pmn_index.segID.isin(pmn_annotation_table.loc[pmn_annotation_table.cell_type==ctype,'pt_root_id']),'cell_type'] = ctype\n",
    "\n",
    "pre_to_mn_df.index = pd.MultiIndex.from_frame(pmn_index)\n",
    "pre_to_mn_df = pre_to_mn_df.reorder_levels(['cell_class','preferred_pool','classification_system','cell_type','segID'],'index')\n",
    "pre_to_mn_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add neurotransmitters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create lookuptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = pre_to_mn_df.index.get_level_values('cell_type').unique().to_numpy()\n",
    "nt_table = pd.read_csv('./annotations_hl/LacinHLTable.csv')\n",
    "import re\n",
    "pattern = re.compile(\"R[0-9]\")\n",
    "\n",
    "hl_lut = {'cell_type':cell_types,'hemilineage':cell_types}\n",
    "hl_lut = pd.DataFrame(data=hl_lut)\n",
    "\n",
    "for idx,r in hl_lut.iterrows():\n",
    "    try:\n",
    "        if np.isnan(r.hemilineage):\n",
    "            continue\n",
    "    except TypeError:\n",
    "        pass\n",
    "    hl = r.hemilineage\n",
    "\n",
    "    if hl[0:2]=='RD':\n",
    "        hl = '24B'\n",
    "        # print('string was RD, now {}'.format(hl))\n",
    "\n",
    "    if pattern.match(hl) or hl=='RVD' or hl=='Rcore_':\n",
    "        # print('string was {}, now 8A'.format(hl))\n",
    "        hl = '8A'\n",
    "\n",
    "    if not hl.isalnum():\n",
    "        hl = hl[0:-1]\n",
    "        # print(hl)\n",
    "    \n",
    "    if not hl.isalnum():\n",
    "        hl=hl[0:hl.find('_')]\n",
    "        # print(hl)\n",
    "\n",
    "    if hl == '9Ac':\n",
    "        hl='9A'\n",
    "        # print(hl)\n",
    "\n",
    "    hl_lut.loc[idx,'hemilineage'] = hl\n",
    "\n",
    "# merge with neurotransmitter table to get a lookuptable\n",
    "hl_lut = hl_lut.merge(nt_table,how='outer',left_on='hemilineage',right_on='HL')\n",
    "hl_lut = hl_lut.loc[~hl_lut.hemilineage.isna(),:]\n",
    "\n",
    "hl_lut_reduced = hl_lut[['cell_type','NT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just operate on the index, where the nt will be\n",
    "pmn_index_df = pre_to_mn_df.index.to_frame().reset_index(drop=True)\n",
    "\n",
    "# join the index on cell_type, with NT\n",
    "pmn_index_df = pmn_index_df.join(hl_lut_reduced.set_index('cell_type'),how='left',on='cell_type')\n",
    "\n",
    "# reorder the matrix\n",
    "pmn_index_df = pmn_index_df[['cell_class','preferred_pool','NT','classification_system','cell_type','segID']]\n",
    "pmn_index_df.NT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are some local neurons that don't have hemilineages\n",
    "pmn_index_df.loc[(pmn_index_df.cell_class=='local') & (pmn_index_df.classification_system.isna())].segID.values\n",
    "\n",
    "# 8/3 just updated the premotor neuron table to add the segIDs I found earlier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now add the sensory neuron classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sensory = connectome_create.get_unduplicated_sensory_axon_table(client)\n",
    "\n",
    "all_sensory = all_sensory[['pt_root_id','classification_system','cell_type']]\n",
    "all_sensory = all_sensory.rename({'pt_root_id':'segID'},axis=1)\n",
    "\n",
    "# join the index on cell_type, with NT\n",
    "pmn_index_df = pmn_index_df.merge(all_sensory,how='left',on='segID',suffixes=['_x','_y'])\n",
    "\n",
    "sens_rows = (pmn_index_df.cell_class == 'sensory') & (pmn_index_df.classification_system_x.isna())\n",
    "pmn_index_df.loc[sens_rows,'classification_system_x'] = pmn_index_df.loc[sens_rows].classification_system_y\n",
    "pmn_index_df.loc[sens_rows,'cell_type_x'] = pmn_index_df.loc[sens_rows].cell_type_y\n",
    "\n",
    "pmn_index_df.loc[pmn_index_df.cell_class == 'sensory','NT'] = 'Ach'\n",
    "pmn_index_df = pmn_index_df.drop(['classification_system_y','cell_type_y'],axis=1)\n",
    "pmn_index_df = pmn_index_df.rename(columns={'classification_system_x':'classification_system','cell_type_x':'cell_type'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_to_mn_df.index = pd.MultiIndex.from_frame(pmn_index_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectome_create.save_pre_to_mn_df(pre_to_mn_df,ext='matched_typed_with_nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_to_mn_df.loc['intersegmental'].index.to_frame().to_csv('./dfs_saved/intersegmental_ns_20230524_for_Ellen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_to_mn_df.index.to_frame().reset_index(drop=True).to_csv('./dfs_saved/segIDs_to_make_public_20230524.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now print the segids for 13A as an example, then color them in neuroglancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All = slice(None)\n",
    "pmn_index_df = pmn_index.set_index(keys=['cell_class','preferred_pool','classification_system','cell_type'],drop=False)\n",
    "eg13A = pmn_index_df.loc[('local',All,'D', All,),:]\n",
    "\n",
    "\n",
    "for pl in eg13A.preferred_pool.unique():\n",
    "    print(eg13A.loc[(All,pl,All),'segID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmn_index.classification_system.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the number of synapes from different types to MFT, SET, Aux B, Aux E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpool_dict = utils.get_motor_pool_tuple_dict()\n",
    "# pool_keys = [\n",
    "#     'thorax_swing',\n",
    "#     'tibia_extensor',\n",
    "#     'main_tibia_flexor',\n",
    "#     'auxiliary_tibia_flexor_B',\n",
    "#     'auxiliary_tibia_flexor_E',\n",
    "#     ]\n",
    "\n",
    "# local = pre_to_mn_df.loc['local']\n",
    "# for pk in pool_keys:\n",
    "#     local_to_pool = local.loc[:,mpool_dict[pk]]\n",
    "\n",
    "#     labels = sorted(local_to_pool.index.unique(level='classification_system'))\n",
    "#     sizes = []\n",
    "#     for lbl in labels:\n",
    "#         ttlsyn = local_to_pool.loc[(All,lbl),:].sum().sum()\n",
    "#         sizes = sizes+[ttlsyn]\n",
    "\n",
    "\n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     ax1.pie(sizes, explode=None, labels=labels, autopct='%1.0f%%',\n",
    "#             shadow=False, startangle=90)\n",
    "#     ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "#     fname = './figpanels/{}_hl_input_pie.svg'.format(pk)\n",
    "#     fig1.savefig(fname,format='svg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find untyped neurons to type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmn_index.loc[(pmn_index.cell_class=='local') & pmn_index.classification_system.isnull()].segID.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untyped_inter = pmn_index.loc[(pmn_index.cell_class=='intersegmental') & pmn_index.classification_system.isnull()]\n",
    "utils.save_df_csv(untyped_inter,name='untyped_interstegmenal_neurons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b93c3ce0f0b01938714f8d6ce3882059af39419bb08f14e121c5729b1321faa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
